{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FireBee\\anaconda3\\envs\\tf\\lib\\site-packages\\pylearn_parsimony-0.3.1-py3.7.egg\\parsimony\\config.py:55: RuntimeWarning: Could not locate the config file.\n"
     ]
    }
   ],
   "source": [
    "from scipy import sparse\n",
    "import pandas\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import parsimony.estimators as estimators\n",
    "import parsimony.algorithms as algorithms\n",
    "import parsimony.functions.nesterov.tv as tv\n",
    "import sklearn.preprocessing \n",
    "\n",
    "def Ak_from_pairs(k,p):\n",
    "    Ak = sparse.lil_matrix((int(p*(p-1)/2),p*p))\n",
    "    ij=0\n",
    "    for i in range(0,p-1):\n",
    "        for j in range(i+1,p):\n",
    "            #print(i*p+k,j*p+k,ij)\n",
    "            if (i==k)|(j==k):\n",
    "                Ak[ij,i*p+j]=1\n",
    "                Ak[ij,j*p+i]=-1\n",
    "            else:\n",
    "                Ak[ij,i*p+k]=1\n",
    "                Ak[ij,j*p+k]=-1\n",
    "            ij=ij+1\n",
    "    #return(Ak)\n",
    "       \n",
    "    to_keep = list(set(range(Ak.shape[1]))-set(range(0,p*p,p+1)))    \n",
    "    Aknew = sparse.lil_matrix(sparse.csr_matrix(Ak)[:,to_keep])     \n",
    "    return(Aknew)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def linear_operator_from_num_variables(num_variables):\n",
    "    \"\"\"Generates the linear operator for the TV lasso Nesterov function\n",
    "    from number of variables.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    num_variables : Integer. The total number of variables, including the\n",
    "            intercept variable(s).\n",
    "\n",
    "    \"\"\"\n",
    "    A = list()\n",
    "    for k in range(0,num_variables):\n",
    "        Ak = Ak_from_pairs(k,num_variables)\n",
    "        A.append(Ak.tocsr())\n",
    "    return A\n",
    "\n",
    "def beta2Beta(beta,p): \n",
    "    Beta=np.zeros((p,p))\n",
    "    for j in range(0,(p-1)):\n",
    "        for i in range(0,p):\n",
    "            k=i\n",
    "            l=j\n",
    "            if j>=i:\n",
    "                l=j+1\n",
    "            Beta[k,l]=beta[i*(p-1)+j]\n",
    "    return(Beta)  \n",
    "\n",
    "def precision2regression(K):\n",
    "    p=K.shape[0]\n",
    "    M=np.zeros((p,p))\n",
    "    for i in range(0,p):\n",
    "        for j in range(0,p):\n",
    "            if i!=j:\n",
    "                M[i,j]= - K[i,j]/K[i,i]\n",
    "    return(M)     \n",
    "\n",
    "\n",
    "def conesta_rwrapper(X, lam1, lam2):\n",
    "    X=np.array(X)\n",
    "    n=X.shape[0]\n",
    "    p=X.shape[1]\n",
    "  \n",
    "    X=sklearn.preprocessing.scale(X)\n",
    "    y=X.reshape(n*p,1,order='F')\n",
    "    Xvec=np.delete(np.kron(np.identity(p),X),range(0,p*p,p+1),axis=1)\n",
    "    A=linear_operator_from_num_variables(p)\n",
    "  \n",
    "    l = lam1  # l1 lasso coefficient\n",
    "    k = 0.0  # l2 ridge regression coefficient\n",
    "    g = lam2 \n",
    "  \n",
    "    hgmm = estimators.LinearRegressionL1L2TV(l, k, g, A, mu=0.001,\n",
    "                                           algorithm=algorithms.proximal.CONESTA(max_iter=1000), mean=False)\n",
    "    res = hgmm.fit(Xvec,y)\n",
    "    Beta=beta2Beta(res.beta,p)\n",
    "    #print(res.score(Xvec, y))\n",
    "  \n",
    "    return(Beta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minus and plus lines with reodering the coefficients\n",
    "\n",
    "def minus_lines(i, j, Beta, ni = 1, nj = 1):\n",
    "    Y_coeffs = Beta[i, :].copy()\n",
    "    X_coeffs = Beta[j, :].copy()\n",
    "    X_i = X_coeffs[i]\n",
    "    X_coeffs[i] = X_coeffs[j]\n",
    "    X_coeffs[j] = X_i\n",
    "    return ni*Y_coeffs - nj*X_coeffs\n",
    "\n",
    "def plus_lines(i, j, Beta, ni = 1, nj = 1):\n",
    "    Y_coeffs = Beta[i, :].copy()\n",
    "    X_coeffs = Beta[j, :].copy()\n",
    "    X_i = X_coeffs[i]\n",
    "    X_coeffs[i] = X_coeffs[j]\n",
    "    X_coeffs[j] = X_i\n",
    "    return ni*Y_coeffs + nj*X_coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cost function\n",
    "\n",
    "def cost(Beta, X, lambda1=0, lambda2=0):\n",
    "    p = X.shape[1]\n",
    "    P2 = 0\n",
    "    L = 0\n",
    "    # loss term\n",
    "    if (p > 1):\n",
    "        L = np.sum(np.vectorize(lambda i: np.linalg.norm(X[:,i] - X @ Beta[i,:])**2)(range(p)))\n",
    "\n",
    "        # fuse-group lasso penalty\n",
    "        for i in range(p-1):\n",
    "            for j in range(i+1,p):\n",
    "                P2 = P2 + np.linalg.norm(minus_lines(i, j, Beta))\n",
    "\n",
    "    # lasso penalty\n",
    "    P1 = np.sum(np.abs(Beta))\n",
    "    \n",
    "    return L + lambda1*P1 + lambda2*P2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distances Beta\n",
    "def dist_beta(Beta, distance = \"euclidean\"):\n",
    "    K = Beta.shape[1]\n",
    "    \n",
    "    if (K != 1):\n",
    "        diffs = np.ones((K, K))*np.inf\n",
    "        for i in range(K-1):\n",
    "            for j in range(i+1,K):\n",
    "                diffs[i,j] = np.linalg.norm(minus_lines(i, j, Beta))\n",
    "    \n",
    "        if (distance == \"relative\"):\n",
    "            Dsum = np.ones((K, K))\n",
    "            for i in range(K-1):\n",
    "                for j in range(i+1,K):\n",
    "                    Dsum[i,j] = np.linalg.norm(Beta[i,:]) + np.linalg.norm(Beta[j,:])\n",
    "\n",
    "            diffs = diffs/Dsum\n",
    "\n",
    "    else:\n",
    "        diffs = np.zeros((1,1))\n",
    "  \n",
    "    return diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge X\n",
    "def mergeX(X, pair_to_merge, clusters):\n",
    "    X = X.copy()\n",
    "    i = np.min(pair_to_merge)\n",
    "    j = np.max(pair_to_merge)\n",
    "  \n",
    "    ni = np.sum(clusters == i)\n",
    "    nj = np.sum(clusters == j)\n",
    "  \n",
    "    X[:,i] = (ni*X[:,i] + nj*X[:,j])/(ni + nj)\n",
    "    X = np.delete(X, j, 1)\n",
    "    \n",
    "    return X\n",
    "\n",
    "#' Merge Beta\n",
    "#' Different types of merging and their effect\n",
    "def merge_beta(Beta, pair_to_merge, clusters):\n",
    "    Beta = Beta.copy()\n",
    "    i = min(pair_to_merge)\n",
    "    j = max(pair_to_merge)\n",
    "  \n",
    "    ni = np.sum(clusters == i)\n",
    "    nj = np.sum(clusters == j)\n",
    "  \n",
    "    Beta[i,:] = plus_lines(i, j, Beta, ni, nj) / (ni + nj)\n",
    "    Beta = np.delete(np.delete(Beta, j, 1), j, 0)\n",
    "  \n",
    "    return Beta\n",
    "\n",
    "#' Merge labels\n",
    "def merge_labels(merged_pair, labels):\n",
    "    i = min(merged_pair)\n",
    "    j = max(merged_pair)\n",
    "    labels[i] = max(labels)+1\n",
    "    labels = np.delete(labels, j , None)\n",
    "    return labels\n",
    "\n",
    "#' Merge counts\n",
    "def merge_counts(merged_pair, counts):\n",
    "    i = min(merged_pair)\n",
    "    j = max(merged_pair)\n",
    "    counts[i] = counts[i]+counts[j]\n",
    "    counts = np.delete(counts, j , None)\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_proc(pairs_to_merge, \n",
    "               clusters, \n",
    "               X,\n",
    "               Beta,\n",
    "               level,\n",
    "               gain_level,\n",
    "               gains,\n",
    "               labels,\n",
    "               merge,\n",
    "               counts,\n",
    "               size):\n",
    "    X = X.copy()\n",
    "    Beta = Beta.copy()\n",
    "    for l in range(pairs_to_merge.shape[0]):\n",
    "        pair_to_merge = pairs_to_merge[l,:]\n",
    "    \n",
    "        # can also take the 1st element cause it's always the min for a upper-triangular matrix\n",
    "        i = np.min(pair_to_merge)\n",
    "        j = np.max(pair_to_merge)\n",
    "    \n",
    "        if(i != j):\n",
    "            \n",
    "            # update size of clusters\n",
    "            size[level] = counts[i] + counts[j]\n",
    "            counts = merge_counts(pair_to_merge, counts)\n",
    "      \n",
    "            # merge lines/cols in Beta and X\n",
    "            Beta = merge_beta(Beta, pair_to_merge, clusters)\n",
    "            X = mergeX(X, pair_to_merge, clusters)\n",
    "      \n",
    "            # update dendrogram\n",
    "            merge[level, :] = [labels[i], labels[j]]\n",
    "            labels = merge_labels(pair_to_merge, labels)\n",
    "            gains[level-1] = 0 if l>0 else np.nan\n",
    "      \n",
    "            # merge clusters\n",
    "            clusters[clusters == j] = i \n",
    "            clusters[clusters > j] = clusters[clusters > j] - 1\n",
    "      \n",
    "            # update the rest of the table with the new clusters\n",
    "            pairs_to_merge[pairs_to_merge == j] = i\n",
    "            pairs_to_merge[pairs_to_merge > j] = pairs_to_merge[pairs_to_merge > j] - 1\n",
    "            \n",
    "            level = level + 1\n",
    "            \n",
    "    out_mergeproc = {\"clusters\" : clusters, \n",
    "                     \"Beta\" : Beta, \n",
    "                     \"X\" : X, \n",
    "                     \"level\" : level, \n",
    "                     \"gains\" : gains, \n",
    "                     \"merge\" : merge, \n",
    "                     \"labels\" : labels,\n",
    "                     \"counts\" : counts,\n",
    "                     \"size\" : size}\n",
    "    return(out_mergeproc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hggm2(X, \n",
    "          lambda1=0, \n",
    "          fuse_thresh = 1e-3, \n",
    "          maxit = 1000, \n",
    "          silent = True, \n",
    "          distance = \"euclidean\", \n",
    "          solver = \"conesta\", \n",
    "          lambda2_start = 1e-4, \n",
    "          lambda2_factor = 1.5):\n",
    "    ## Initialisations\n",
    "    X = X.copy()\n",
    "    X = np.array(X)\n",
    "    p = X.shape[1]\n",
    "    gains = np.zeros(p-1)\n",
    "    merge = np.zeros((p-1, 2)) # matrix of merging clusters at each level\n",
    "    old_level = level = 0\n",
    "    labels = np.arange(p)   # vector of clusters labels\n",
    "    clusters = np.arange(p)\n",
    "    counts = np.ones(p)\n",
    "    height = np.zeros(p-1)\n",
    "    size = np.zeros(p-1)\n",
    "    \n",
    "    lambda2 = lambda2_start\n",
    "    old_lambda2 = 0\n",
    "    old_lambda1 = lambda1\n",
    "    Beta = conesta_rwrapper(X, lambda1, old_lambda2)\n",
    "  \n",
    "    old_costf = costf =  cost(Beta, X, lambda1, old_lambda2)\n",
    "  \n",
    "    t = 0 # index for the out list.\n",
    "    iteration = 0\n",
    "    out = []\n",
    "    out = np.append(out, {\"Beta\" : Beta, \"clusters\" : clusters.copy()})\n",
    "    #names(out)[[1]] = \"level0\"\n",
    "    prev = len(np.unique(clusters))\n",
    "    ## End Initialisations\n",
    "  \n",
    "  \n",
    "    ## Loop until all the variables merged\n",
    "    while (len(np.unique(clusters)) > 1):\n",
    "        oldp = X.shape[1]\n",
    "        #iteration = iteration + 1\n",
    "    \n",
    "        Beta = conesta_rwrapper(X, lambda1, lambda2)\n",
    "    \n",
    "        ## Update distance matrix\n",
    "        diffs = dist_beta(Beta, distance = distance)\n",
    "    \n",
    "        ## Clustering starts here\n",
    "        pairs_to_merge = np.concatenate(np.where(diffs<=fuse_thresh)).reshape((2,-1)).T\n",
    "    \n",
    "        if (pairs_to_merge.shape[0] != 0):\n",
    "            \n",
    "            gain_level = costf - old_costf\n",
    "            out_mergeproc = merge_proc(pairs_to_merge, clusters, X, Beta, level, gain_level, gains, labels, merge, counts, size)\n",
    "\n",
    "            X        = out_mergeproc['X']\n",
    "            Beta     = out_mergeproc['Beta']\n",
    "            clusters = out_mergeproc['clusters']\n",
    "\n",
    "            level    = out_mergeproc['level']\n",
    "            gains    = out_mergeproc['gains']\n",
    "            merge    = out_mergeproc['merge']\n",
    "            labels   = out_mergeproc['labels'] \n",
    "            counts   = out_mergeproc['counts']\n",
    "            size   = out_mergeproc['size']\n",
    "            height[old_level:level] = lambda2\n",
    "            \n",
    "            old_level = level\n",
    "    ## Clustering ends here\n",
    "    \n",
    "        costf = cost(Beta, X, lambda1, lambda2)\n",
    "        #cat(\"nclusters =\", length(unique(clusters)), \"lambda2\", lambda2, \"cost =\", costf, \"\\n\")\n",
    "        print(\"nclusters: \", len(np.unique(clusters)), \"lambda2 :\", lambda2, \"cost: \", costf)\n",
    "        \n",
    "        gains[np.isnan(gains)] = old_costf - costf\n",
    "        old_costf = costf\n",
    "    \n",
    "        if(len(np.unique(clusters)) != prev):\n",
    "            out = np.append(out, {\"Beta\" : Beta, \"clusters\" : clusters.copy()})\n",
    "            #names(out)[[t]] <- paste0(\"level\", (p-length(unique(clusters))))\n",
    "            prev = len(np.unique(clusters))\n",
    "            t = t + 1\n",
    "    \n",
    "        old_lambda2 = lambda2\n",
    "    \n",
    "        lambda2 = lambda2*lambda2_factor\n",
    "        \n",
    "    tree = np.c_[merge, height, size]\n",
    "  \n",
    "    result = {\"out\" : out, \"tree\" : tree}\n",
    "  \n",
    "    return(result) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pandas.read_csv(\"toy_example.csv\")\n",
    "#X = pandas.read_csv(\"test.txt\", delimiter=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nclusters:  5 lambda2 : 0.0001 cost:  185.96724514067725\n",
      "nclusters:  5 lambda2 : 0.00015000000000000001 cost:  185.96737113060146\n",
      "nclusters:  5 lambda2 : 0.00022500000000000002 cost:  185.9675601227048\n",
      "nclusters:  5 lambda2 : 0.0003375 cost:  185.96784360981488\n",
      "nclusters:  5 lambda2 : 0.00050625 cost:  185.96826883836127\n",
      "nclusters:  5 lambda2 : 0.000759375 cost:  185.96890667464223\n",
      "nclusters:  5 lambda2 : 0.0011390624999999999 cost:  185.96986341760783\n",
      "nclusters:  5 lambda2 : 0.0017085937499999998 cost:  185.97129850619086\n",
      "nclusters:  5 lambda2 : 0.0025628906249999996 cost:  185.97345107996586\n",
      "nclusters:  5 lambda2 : 0.0038443359374999994 cost:  185.97667980159483\n",
      "nclusters:  5 lambda2 : 0.00576650390625 cost:  185.98152258345002\n",
      "nclusters:  5 lambda2 : 0.008649755859375 cost:  185.9887860666679\n",
      "nclusters:  5 lambda2 : 0.0129746337890625 cost:  185.99967970912672\n",
      "nclusters:  5 lambda2 : 0.01946195068359375 cost:  186.01601656064466\n",
      "nclusters:  5 lambda2 : 0.029192926025390625 cost:  186.04051347880602\n",
      "nclusters:  5 lambda2 : 0.043789389038085935 cost:  186.07723930976167\n",
      "nclusters:  5 lambda2 : 0.0656840835571289 cost:  186.13228168953188\n",
      "nclusters:  5 lambda2 : 0.09852612533569335 cost:  186.21473281017958\n",
      "nclusters:  5 lambda2 : 0.14778918800354002 cost:  186.33813025378487\n",
      "nclusters:  5 lambda2 : 0.22168378200531003 cost:  186.52251424326582\n",
      "nclusters:  5 lambda2 : 0.33252567300796504 cost:  186.79722591215202\n",
      "nclusters:  5 lambda2 : 0.49878850951194753 cost:  187.20431178052453\n",
      "nclusters:  5 lambda2 : 0.7481827642679213 cost:  187.80149730098842\n",
      "nclusters:  5 lambda2 : 1.122274146401882 cost:  188.66113472247574\n",
      "nclusters:  5 lambda2 : 1.683411219602823 cost:  189.85494051574662\n",
      "nclusters:  5 lambda2 : 2.5251168294042348 cost:  191.395571534083\n",
      "nclusters:  2 lambda2 : 3.787675244106352 cost:  49.459077423348425\n",
      "nclusters:  1 lambda2 : 5.681512866159528 cost:  0.0\n"
     ]
    }
   ],
   "source": [
    "m = hggm2(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         3.         3.78767524 2.        ]\n",
      " [1.         2.         3.78767524 2.        ]\n",
      " [5.         6.         3.78767524 4.        ]\n",
      " [7.         4.         5.68151287 5.        ]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.cluster import hierarchy\n",
    "dn = hierarchy.dendrogram(m['tree'])\n",
    "print(m['tree'])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
