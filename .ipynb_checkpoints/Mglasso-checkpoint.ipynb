{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FireBee\\anaconda3\\envs\\tf\\lib\\site-packages\\pylearn_parsimony-0.3.1-py3.7.egg\\parsimony\\config.py:55: RuntimeWarning: Could not locate the config file.\n"
     ]
    }
   ],
   "source": [
    "from scipy import sparse\n",
    "import pandas\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import parsimony.estimators as estimators\n",
    "import parsimony.algorithms as algorithms\n",
    "import parsimony.functions.nesterov.tv as tv\n",
    "import sklearn.preprocessing \n",
    "\n",
    "def Ak_from_pairs(k,p):\n",
    "    Ak = sparse.lil_matrix((int(p*(p-1)/2),p*p))\n",
    "    ij=0\n",
    "    for i in range(0,p-1):\n",
    "        for j in range(i+1,p):\n",
    "            #print(i*p+k,j*p+k,ij)\n",
    "            if (i==k)|(j==k):\n",
    "                Ak[ij,i*p+j]=1\n",
    "                Ak[ij,j*p+i]=-1\n",
    "            else:\n",
    "                Ak[ij,i*p+k]=1\n",
    "                Ak[ij,j*p+k]=-1\n",
    "            ij=ij+1\n",
    "    #return(Ak)\n",
    "       \n",
    "    to_keep = list(set(range(Ak.shape[1]))-set(range(0,p*p,p+1)))    \n",
    "    Aknew = sparse.lil_matrix(sparse.csr_matrix(Ak)[:,to_keep])     \n",
    "    return(Aknew)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def linear_operator_from_num_variables(num_variables):\n",
    "    \"\"\"Generates the linear operator for the TV lasso Nesterov function\n",
    "    from number of variables.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    num_variables : Integer. The total number of variables, including the\n",
    "            intercept variable(s).\n",
    "\n",
    "    \"\"\"\n",
    "    A = list()\n",
    "    for k in range(0,num_variables):\n",
    "        Ak = Ak_from_pairs(k,num_variables)\n",
    "        A.append(Ak.tocsr())\n",
    "    return A\n",
    "\n",
    "def beta2Beta(beta,p): \n",
    "    Beta=np.zeros((p,p))\n",
    "    for j in range(0,(p-1)):\n",
    "        for i in range(0,p):\n",
    "            k=i\n",
    "            l=j\n",
    "            if j>=i:\n",
    "                l=j+1\n",
    "            Beta[k,l]=beta[i*(p-1)+j]\n",
    "    return(Beta)  \n",
    "\n",
    "def precision2regression(K):\n",
    "    p=K.shape[0]\n",
    "    M=np.zeros((p,p))\n",
    "    for i in range(0,p):\n",
    "        for j in range(0,p):\n",
    "            if i!=j:\n",
    "                M[i,j]= - K[i,j]/K[i,i]\n",
    "    return(M)     \n",
    "\n",
    "\n",
    "def conesta_rwrapper(X, lam1, lam2):\n",
    "    X=np.array(X)\n",
    "    n=X.shape[0]\n",
    "    p=X.shape[1]\n",
    "  \n",
    "    X=sklearn.preprocessing.scale(X)\n",
    "    y=X.reshape(n*p,1,order='F')\n",
    "    Xvec=np.delete(np.kron(np.identity(p),X),range(0,p*p,p+1),axis=1)\n",
    "    A=linear_operator_from_num_variables(p)\n",
    "  \n",
    "    l = lam1  # l1 lasso coefficient\n",
    "    k = 0.0  # l2 ridge regression coefficient\n",
    "    g = lam2 \n",
    "  \n",
    "    hgmm = estimators.LinearRegressionL1L2TV(l, k, g, A, mu=0.001,\n",
    "                                           algorithm=algorithms.proximal.CONESTA(max_iter=1000), mean=False)\n",
    "    res = hgmm.fit(Xvec,y)\n",
    "    Beta=beta2Beta(res.beta,p)\n",
    "    #print(res.score(Xvec, y))\n",
    "  \n",
    "    return(Beta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minus and plus lines with reodering the coefficients\n",
    "\n",
    "def minus_lines(i, j, Beta, ni = 1, nj = 1):\n",
    "    Y_coeffs = Beta[i, :].copy()\n",
    "    X_coeffs = Beta[j, :].copy()\n",
    "    X_i = X_coeffs[i]\n",
    "    X_coeffs[i] = X_coeffs[j]\n",
    "    X_coeffs[j] = X_i\n",
    "    return ni*Y_coeffs - nj*X_coeffs\n",
    "\n",
    "def plus_lines(i, j, Beta, ni = 1, nj = 1):\n",
    "    Y_coeffs = Beta[i, :].copy()\n",
    "    X_coeffs = Beta[j, :].copy()\n",
    "    X_i = X_coeffs[i]\n",
    "    X_coeffs[i] = X_coeffs[j]\n",
    "    X_coeffs[j] = X_i\n",
    "    return ni*Y_coeffs + nj*X_coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cost function\n",
    "\n",
    "def cost(Beta, X, lambda1=0, lambda2=0):\n",
    "    p = X.shape[1]\n",
    "    P2 = 0\n",
    "    L = 0\n",
    "    # loss term\n",
    "    if (p > 1):\n",
    "        L = np.sum(np.vectorize(lambda i: np.linalg.norm(X[:,i] - X @ Beta[i,:])**2)(range(p)))\n",
    "\n",
    "        # fuse-group lasso penalty\n",
    "        for i in range(p-1):\n",
    "            for j in range(i+1,p):\n",
    "                P2 = P2 + np.linalg.norm(minus_lines(i, j, Beta))\n",
    "\n",
    "    # lasso penalty\n",
    "    P1 = np.sum(np.abs(Beta))\n",
    "    \n",
    "    return L + lambda1*P1 + lambda2*P2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distances Beta\n",
    "def dist_beta(Beta, distance = \"euclidean\"):\n",
    "    K = Beta.shape[1]\n",
    "    \n",
    "    if (K != 1):\n",
    "        diffs = np.ones((K, K))*np.inf\n",
    "        for i in range(K-1):\n",
    "            for j in range(i+1,K):\n",
    "                diffs[i,j] = np.linalg.norm(minus_lines(i, j, Beta))\n",
    "    \n",
    "        if (distance == \"relative\"):\n",
    "            Dsum = np.ones((K, K))\n",
    "            for i in range(K-1):\n",
    "                for j in range(i+1,K):\n",
    "                    Dsum[i,j] = np.linalg.norm(Beta[i,:]) + np.linalg.norm(Beta[j,:])\n",
    "\n",
    "            diffs = diffs/Dsum\n",
    "\n",
    "    else:\n",
    "        diffs = np.zeros((1,1))\n",
    "  \n",
    "    return diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge X\n",
    "def mergeX(X, pair_to_merge, clusters):\n",
    "    X = X.copy()\n",
    "    i = np.min(pair_to_merge)\n",
    "    j = np.max(pair_to_merge)\n",
    "  \n",
    "    ni = np.sum(clusters == i)\n",
    "    nj = np.sum(clusters == j)\n",
    "  \n",
    "    X[:,i] = (ni*X[:,i] + nj*X[:,j])/(ni + nj)\n",
    "    X = np.delete(X, j, 1)\n",
    "    \n",
    "    return X\n",
    "\n",
    "#' Merge Beta\n",
    "#' Different types of merging and their effect\n",
    "def merge_beta(Beta, pair_to_merge, clusters):\n",
    "    Beta = Beta.copy()\n",
    "    i = min(pair_to_merge)\n",
    "    j = max(pair_to_merge)\n",
    "  \n",
    "    ni = np.sum(clusters == i)\n",
    "    nj = np.sum(clusters == j)\n",
    "  \n",
    "    Beta[i,:] = plus_lines(i, j, Beta, ni, nj) / (ni + nj)\n",
    "    Beta = np.delete(np.delete(Beta, j, 1), j, 0)\n",
    "  \n",
    "    return Beta\n",
    "\n",
    "#' Merge labels\n",
    "def merge_labels(merged_pair, labels, level):\n",
    "    i = min(merged_pair)\n",
    "    j = max(merged_pair)\n",
    "    labels[i] = level\n",
    "    labels = np.delete(labels, j , None)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_proc(pairs_to_merge, \n",
    "               clusters, \n",
    "               X,\n",
    "               Beta,\n",
    "               level,\n",
    "               gain_level,\n",
    "               gains,\n",
    "               labels,\n",
    "               merge):\n",
    "    X = X.copy()\n",
    "    Beta = Beta.copy()\n",
    "    for l in range(pairs_to_merge.shape[0]):\n",
    "        pair_to_merge = pairs_to_merge[l,:]\n",
    "    \n",
    "        # can also take the 1st element cause it's always the min for a upper-triangular matrix\n",
    "        i = np.min(pair_to_merge)\n",
    "        j = np.max(pair_to_merge)\n",
    "    \n",
    "        if(i != j):\n",
    "      \n",
    "            # merge lines/cols in Beta and X\n",
    "            Beta = merge_beta(Beta, pair_to_merge, clusters)\n",
    "            X = mergeX(X, pair_to_merge, clusters)\n",
    "      \n",
    "            # update dendrogram\n",
    "            merge[level, :] = [labels[i], labels[j]]\n",
    "            labels = merge_labels(pair_to_merge, labels, level)\n",
    "            gains[level-1] = 0 if l>0 else np.nan\n",
    "      \n",
    "            # merge clusters\n",
    "            clusters[clusters == j] = i \n",
    "            clusters[clusters > j] = clusters[clusters > j] - 1\n",
    "      \n",
    "            # update the rest of the table with the new clusters\n",
    "            pairs_to_merge[pairs_to_merge == j] = i\n",
    "            pairs_to_merge[pairs_to_merge > j] = pairs_to_merge[pairs_to_merge > j] - 1\n",
    "            \n",
    "            level = level + 1\n",
    "            \n",
    "    out_mergeproc = {\"clusters\" : clusters, \n",
    "                     \"Beta\" : Beta, \n",
    "                     \"X\" : X, \n",
    "                     \"level\" : level, \n",
    "                     \"gains\" : gains, \n",
    "                     \"merge\" : merge, \n",
    "                     \"labels\" : labels}\n",
    "    return(out_mergeproc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hggm2(X, \n",
    "          lambda1=0, \n",
    "          fuse_thresh = 1e-3, \n",
    "          maxit = 1000, \n",
    "          silent = True, \n",
    "          distance = \"euclidean\", \n",
    "          solver = \"conesta\", \n",
    "          lambda2_start = 1e-4, \n",
    "          lambda2_factor = 1.5):\n",
    "    ## Initialisations\n",
    "    X = X.copy()\n",
    "    X = np.array(X)\n",
    "    p = X.shape[1]\n",
    "    gains = np.zeros(p-1)\n",
    "    merge = np.zeros((p-1, 2)) # matrix of merging clusters at each level\n",
    "    level = 0\n",
    "    labels = -np.arange(p)                         # vector of clusters labels\n",
    "    clusters = np.arange(p)\n",
    "  \n",
    "    lambda2 = lambda2_start\n",
    "    old_lambda2 = 0\n",
    "    old_lambda1 = lambda1\n",
    "    Beta = conesta_rwrapper(X, lambda1, old_lambda2)\n",
    "  \n",
    "    old_costf = costf =  cost(Beta, X, lambda1, old_lambda2)\n",
    "  \n",
    "  \n",
    "    t = 0 # index for the out list.\n",
    "    iteration = 0\n",
    "    out = []\n",
    "    out = np.append(out, {\"Beta\" : Beta, \"clusters\" : clusters.copy()})\n",
    "    #names(out)[[1]] = \"level0\"\n",
    "    prev = len(np.unique(clusters))\n",
    "    ## End Initialisations\n",
    "  \n",
    "  \n",
    "    ## Loop until all the variables merged\n",
    "    while (len(np.unique(clusters)) > 1):\n",
    "        oldp = X.shape[1]\n",
    "        iteration = iteration + 1\n",
    "    \n",
    "    \n",
    "        Beta = conesta_rwrapper(X, lambda1, lambda2)\n",
    "    \n",
    "        ## Update distance matrix\n",
    "        diffs = dist_beta(Beta, distance = distance)\n",
    "    \n",
    "        ## Clustering starts here\n",
    "        pairs_to_merge = np.concatenate(np.where(diffs<=fuse_thresh)).reshape((2,-1)).T\n",
    "    \n",
    "        if (pairs_to_merge.shape[0] != 0):\n",
    "            gain_level = costf - old_costf\n",
    "            out_mergeproc = merge_proc(pairs_to_merge, clusters, X, Beta, level, gain_level, gains, labels, merge)\n",
    "\n",
    "            X        = out_mergeproc['X']\n",
    "            Beta     = out_mergeproc['Beta']\n",
    "            clusters = out_mergeproc['clusters']\n",
    "\n",
    "            level    = out_mergeproc['level']\n",
    "            gains    = out_mergeproc['gains']\n",
    "            merge    = out_mergeproc['merge']\n",
    "            labels   = out_mergeproc['labels'] \n",
    "\n",
    "    ## Clustering ends here\n",
    "    \n",
    "        costf = cost(Beta, X, lambda1, lambda2)\n",
    "        #cat(\"nclusters =\", length(unique(clusters)), \"lambda2\", lambda2, \"cost =\", costf, \"\\n\")\n",
    "        print(\"nclusters: \", len(np.unique(clusters)), \"lambda2 :\", lambda2, \"cost: \", costf)\n",
    "        \n",
    "        gains[np.isnan(gains)] = old_costf - costf\n",
    "        old_costf = costf\n",
    "    \n",
    "        if(len(np.unique(clusters)) != prev):\n",
    "            out = np.append(out, {\"Beta\" : Beta, \"clusters\" : clusters.copy()})\n",
    "            #names(out)[[t]] <- paste0(\"level\", (p-length(unique(clusters))))\n",
    "            prev = len(np.unique(clusters))\n",
    "            t = t + 1\n",
    "    \n",
    "        old_lambda2 = lambda2\n",
    "    \n",
    "        lambda2 = lambda2*lambda2_factor\n",
    "  \n",
    "    #height      = cumsum(gains)\n",
    "    #tree        = list(merge = merge,\n",
    "    #                  height = height,\n",
    "    #                  order = rev(clusters),\n",
    "    #                  labels = paste(\"\",1:p),\n",
    "    #                 gains=gains)\n",
    "    #class(tree) = \"hclust\"\n",
    "    #tree = vegan:::reorder.hclust(tree, 1:p)\n",
    "  \n",
    "  \n",
    "    result = out #{\"out\" : out, \"tree\" : tree}\n",
    "  \n",
    "    return(result) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00015000000000000001"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.0001*1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nclusters:  6 lambda2 : 0.0001 cost:  91.56222463063473\n",
      "nclusters:  6 lambda2 : 0.00015000000000000001 cost:  91.563115563533\n",
      "nclusters:  6 lambda2 : 0.00022500000000000002 cost:  91.56445196446819\n",
      "nclusters:  6 lambda2 : 0.0003375 cost:  91.56645656944585\n",
      "nclusters:  6 lambda2 : 0.00050625 cost:  91.5694634849112\n",
      "nclusters:  6 lambda2 : 0.000759375 cost:  91.57397387609177\n",
      "nclusters:  6 lambda2 : 0.0011390624999999999 cost:  91.5807395030439\n",
      "nclusters:  6 lambda2 : 0.0017085937499999998 cost:  91.5908880332612\n",
      "nclusters:  6 lambda2 : 0.0025628906249999996 cost:  91.60611102794495\n",
      "nclusters:  6 lambda2 : 0.0038443359374999994 cost:  91.62894596032889\n",
      "nclusters:  6 lambda2 : 0.00576650390625 cost:  91.66319932219068\n",
      "nclusters:  6 lambda2 : 0.008649755859375 cost:  91.71458143932014\n",
      "nclusters:  6 lambda2 : 0.0129746337890625 cost:  91.79165897171563\n",
      "nclusters:  6 lambda2 : 0.01946195068359375 cost:  91.90728404389694\n",
      "nclusters:  6 lambda2 : 0.029192926025390625 cost:  92.08073800618583\n",
      "nclusters:  6 lambda2 : 0.043789389038085935 cost:  92.34094475077121\n",
      "nclusters:  6 lambda2 : 0.0656840835571289 cost:  92.7312779204482\n",
      "nclusters:  6 lambda2 : 0.09852612533569335 cost:  93.31672144060212\n",
      "nclusters:  6 lambda2 : 0.14778918800354002 cost:  94.19444143028032\n",
      "nclusters:  6 lambda2 : 0.22168378200531003 cost:  95.50914297164188\n",
      "nclusters:  6 lambda2 : 0.33252567300796504 cost:  97.4748127734308\n",
      "nclusters:  6 lambda2 : 0.49878850951194753 cost:  100.40450910082764\n",
      "nclusters:  6 lambda2 : 0.7481827642679213 cost:  104.75002403779092\n",
      "nclusters:  6 lambda2 : 1.122274146401882 cost:  111.1537838062017\n",
      "nclusters:  6 lambda2 : 1.683411219602823 cost:  120.51324980193908\n",
      "nclusters:  6 lambda2 : 2.5251168294042348 cost:  134.0431246985378\n",
      "nclusters:  6 lambda2 : 3.787675244106352 cost:  153.31876004013515\n",
      "nclusters:  6 lambda2 : 5.681512866159528 cost:  180.44293197628647\n",
      "nclusters:  6 lambda2 : 8.52226929923929 cost:  218.94390684496162\n",
      "nclusters:  6 lambda2 : 12.783403948858936 cost:  270.3864769390459\n",
      "nclusters:  1 lambda2 : 19.175105923288406 cost:  0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([{'Beta': array([[ 0.        ,  0.83292469, -0.17282855,  0.14938898,  0.19485267,\n",
       "        -0.33216369],\n",
       "       [ 0.70552117,  0.        ,  0.13841224, -0.14350005, -0.43312032,\n",
       "         0.58684696],\n",
       "       [-0.17607797,  0.1664791 ,  0.        ,  0.76576119, -0.1524089 ,\n",
       "         0.03646563],\n",
       "       [ 0.14712512, -0.16684608,  0.74023925,  0.        ,  0.27577471,\n",
       "        -0.26354385],\n",
       "       [ 0.09218824, -0.24192091, -0.07077664,  0.13248152,  0.        ,\n",
       "         0.94438048],\n",
       "       [-0.14141564,  0.29496184,  0.0152384 , -0.11392784,  0.84981253,\n",
       "         0.        ]]), 'clusters': array([0, 1, 2, 3, 4, 5])},\n",
       "       {'Beta': array([[0.]]), 'clusters': array([0, 0, 0, 0, 0, 0])}],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pandas.read_csv(\"test.txt\", delimiter=\" \")\n",
    "hggm2(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster import hierarchy\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.          6.          0.          2.        ]\n",
      " [ 2.          7.          0.          2.        ]\n",
      " [ 0.          4.          1.          2.        ]\n",
      " [ 1.          8.          1.15470054  3.        ]\n",
      " [ 9.         10.          2.12132034  4.        ]\n",
      " [ 3.         12.          4.11096096  5.        ]\n",
      " [11.         13.         14.07183949  8.        ]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = [[i] for i in [2, 8, 0, 4, 1, 9, 9, 0]]\n",
    "Z = hierarchy.linkage(y, 'ward')\n",
    "print(Z)\n",
    "dn = hierarchy.dendrogram(Z)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
